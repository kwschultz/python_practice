{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "\n",
    "data_dir = \"/Users/kasey/Desktop/kaggle_data/kaggle_titanic_data\"\n",
    "\n",
    "# Plotting parameters\n",
    "sns.set_palette('gist_earth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc056e7871d4e3869d65ab8f52e79de549a3ae4d"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 891\n",
      "Test size: 418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived  Pclass  \\\n",
       "PassengerId                                  \n",
       "1                      1       0.0       3   \n",
       "2                      2       1.0       1   \n",
       "3                      3       1.0       3   \n",
       "4                      4       1.0       1   \n",
       "5                      5       0.0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1309 records, with 12 variables.\n"
     ]
    }
   ],
   "source": [
    "# Read datasets from csv\n",
    "df_train = pd.read_csv('{}/train.csv'.format(data_dir))\n",
    "print(f'Train size: {len(df_train)}')\n",
    "df_test = pd.read_csv('{}/test.csv'.format(data_dir))\n",
    "print(f'Test size: {len(df_test)}')\n",
    "\n",
    "# Merge the 2 dataframes for EDA and feature engineeraing\n",
    "full = pd.concat([df_train, df_test], axis = 0, sort=False)\n",
    "\n",
    "# Set PassengerId as Index\n",
    "full.set_index('PassengerId', drop = False, inplace=True)\n",
    "\n",
    "# Display Data\n",
    "display(full.head())\n",
    "print(f\"Dataset contains {full.shape[0]} records, with {full.shape[1]} variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f103e7ef33077f5a79dbeb16605876af937bbab5"
   },
   "source": [
    "## Missing and Unique Values\n",
    "- Cabin is missing more than 77% of the values, so not useful as a direct feature.\n",
    "- Name is almost entirely unique so not useful as a direct feature, however there titles in there that may provide some social structure or cabin clues, or maybe a proxy for priority into the lifeboats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "f16c4cf2d6f429cd42e30debb0dff655225b1f58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_fraction</th>\n",
       "      <th>unique_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             missing_fraction  unique_fraction\n",
       "Age                     0.201            0.075\n",
       "Cabin                   0.775            0.142\n",
       "Embarked                0.002            0.002\n",
       "Fare                    0.001            0.215\n",
       "Name                    0.000            0.998\n",
       "Parch                   0.000            0.006\n",
       "PassengerId             0.000            1.000\n",
       "Pclass                  0.000            0.002\n",
       "Sex                     0.000            0.002\n",
       "SibSp                   0.000            0.005\n",
       "Survived                0.319            0.002\n",
       "Ticket                  0.000            0.710"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify Missing Values\n",
    "miss_fraction = full.isnull().sum()/len(full)\n",
    "unique_fraction = full.nunique()/len(full)\n",
    "miss_unique = pd.concat([miss_fraction, unique_fraction], axis=1)\n",
    "miss_unique = miss_unique.rename(columns = {0: 'missing_fraction', 1: 'unique_fraction'})\n",
    "miss_unique = miss_unique.apply(lambda x: round(x, 3), axis=0)\n",
    "\n",
    "miss_unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4362db4bb13a8629e6eb62a7cca5d1aa7c22444"
   },
   "source": [
    "## Data Cleaning\n",
    "- simplifying the values of categorical variables\n",
    "- the first few letters of Ticket and Cabin may tell us the location of the passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92409da7d8d62acd2e28140c847c0590405ddea0"
   },
   "source": [
    "### Simplifying the Ticket\n",
    "Tickets provide information on where the passengers are located on ship, which may be vital for survival.\n",
    "Here, I group the tickets by their first few letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44512b0c9a63ca17d58bf3cb73598385176be5b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sort(full['Ticket'].unique())\n",
    "# note: can further explore tcket - cabin - Pclass relationship here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b57ac5743f1eeb9de99a60f4424fe58fa5bc5eb4"
   },
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61fafae9f60511cde56763e478cc7cd6e497352e"
   },
   "outputs": [],
   "source": [
    "def parse_Cabin (cabin):\n",
    "    if type(cabin) == str:\n",
    "        m = re.search(r'([A-Z])+', cabin)\n",
    "        return m.group(1)\n",
    "    else:\n",
    "        return 'X'\n",
    "        \n",
    "full['Cabin_short'] = full['Cabin'].map(parse_Cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40472842d93d5f8e6ffbb3dad3ed6a73319c95dd"
   },
   "source": [
    "###  Fare\n",
    "Fare value was found to be distorted as the Fare feature in original dataset calculates the total amount paid for one single ticket, i.e., no. of person * base rate of ticket. To get a more accurate fare paid by individual value, the fare is divided by the no. of person holding that ticket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cee5aff96f690a7c1d42bb7fef828345526a677f"
   },
   "source": [
    "After adjustment, the range has reduced from 0 - 510 to 0 - 130 and the 3 Pclass are more clearly shown by the 3 peaks of Adjusted Fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "451802b35b1c74b3e19e8aae61011b6eeabc05df"
   },
   "source": [
    "### Missing Fare\n",
    "With fare adjusted, we should be able to fill in the missing Fare value by the Pclass the passenger is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "950d09d94eb805c86c68787307ec56b7d32fc812"
   },
   "outputs": [],
   "source": [
    "# Calculate mean fare cost for each PClass\n",
    "dict_fare_by_Pclass = dict(full.groupby('Pclass').Fare.mean())\n",
    "# fill value according to PClass\n",
    "missing_fare = full.loc[full.Fare.isnull(),'Pclass'].map(dict_fare_by_Pclass)\n",
    "full.loc[full.Fare.isnull(),'Fare'] = missing_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e162bd25360654c38f2dcf44133265f79d0cff4a"
   },
   "source": [
    "## Exploring the Data - Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "554c52adb25ddaa3f656f3328489ba474ff3e98d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "display(full.describe())\n",
    "print(f\"survived: {full.Survived.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a36f4bf5c172fbc786504bd39cec0578e37a5f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EDA - Distributions\n",
    "var_to_plot = ['Pclass','Sex','SibSp','Parch','Embarked','Survived']\n",
    "\n",
    "# Plot Categorical Var\n",
    "fig, axs = plt.subplots(4,3, figsize=(15,12))\n",
    "for i,key in enumerate(var_to_plot):\n",
    "    sns.countplot(key, data=full, ax=axs[i//3,i%3])\n",
    "     \n",
    "# Plot Age\n",
    "plt.subplot2grid((4,3),(2,0),rowspan=1,colspan=3);\n",
    "sns.distplot(full.Age.dropna(), bins=range(0,80,2), kde=False)\n",
    "plt.xlabel('Age');\n",
    "\n",
    "# Plot Fare\n",
    "plt.subplot2grid((4,3),(3,0),rowspan=1,colspan=3);\n",
    "sns.distplot(full.Fare.dropna(), bins=100, kde=False)\n",
    "plt.xlabel('Fare');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d9dbf55133389fc7dc846ff25ef7ef02f872969"
   },
   "source": [
    "## EDA - Relationships between features and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3e5b47fd3cc9baff7dbef21c33f595c10b1ff88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all categorical features with Survival rate\n",
    "var_to_plot = ['Pclass','Sex','SibSp','Parch','Embarked','Cabin_short']\n",
    "\n",
    "f, axs = plt.subplots(3,5, sharey=True)\n",
    "coord = [(0,0),(0,2),(1,0),(1,2),(2,0),(2,2)]\n",
    "for i,key in enumerate(var_to_plot): # except feature Survived\n",
    "    plt.subplot2grid((3,5),(coord[i]),rowspan=1,colspan=2);\n",
    "    sns.barplot(data = full, x= key, y='Survived', color='darkgreen');\n",
    "    plt.axhline(y=0.3838, color='k', linestyle='--')\n",
    "\n",
    "# Plot Correlation\n",
    "corr = pd.DataFrame(full.corr()['Survived'][:-1])\n",
    "plt.subplot2grid((3,5),(0,4),rowspan=3,colspan=1);\n",
    "sns.heatmap(corr, cmap = \"BrBG\", annot = True, annot_kws = {'fontsize': 12 });\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a3c3a197737d839dc2f91d7a9f554b7aa9765ba"
   },
   "source": [
    "Findings:\n",
    "- Sex seems to have a strong predictive power, which makes sense due to the \"Women and Children First\" instructions for deciding who can get on the lifeboats. <br>\n",
    "- Pclass and Fare also showed a moderate correalation with Survival. These higher class passengers lives and have most of their activities near the deck, thus, closer to the lifeboats. <br>\n",
    "- It is surprising to find no significant correlation between Age and Survived. Their relationship may not be linear.\n",
    "- Cabin seem to have some relationships with survival, although we have lots of Nan values in this feature. Perhaps it's possible to guess those Nan values after looking into its relationships with Ticket no., Embark and PClass.\n",
    "- Embark C seem have significantly higher survival rate compared to Embark S, which also have a relatively low variance, There may be a relationship of where they board the Titanic and where they stay on boat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "120c35f687c90847622c794b3aca058ebc9c9f67"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame Features to record potential predictors for later model training\n",
    "features = pd.DataFrame()\n",
    "features['Pclass'] = full['Pclass']\n",
    "features['Fare'] = full['Fare']\n",
    "features['Sex'] = full['Sex']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d87a1e02d23bd43eadff385e8cd80789dab906e0"
   },
   "source": [
    "### Ticket_short with Survival\n",
    "There were still too many types of tickets even after parsing. In the plot below, only those with >10 count are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1afca47a1bacb4050357cc4f75b0f14162e3a981"
   },
   "outputs": [],
   "source": [
    "d = dict(full['Ticket_short'].value_counts())\n",
    "ticket_count = full['Ticket_short'].map(d)\n",
    "# Show % survived by Ticket\n",
    "display(full.groupby('Ticket_short').Survived.aggregate(['mean','count']).dropna().sort_values('count').transpose())\n",
    "# Plot % survived by Ticket, droping those tickets with <10 count\n",
    "sns.barplot(data = full[ticket_count > 10], x = 'Ticket_short', y = 'Survived')\n",
    "plt.axhline(y=0.3838, color='k', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6cda3b38c427eb34bf84dba9e76dfa2418eb619"
   },
   "source": [
    "Tickets with the most Predictive power: A5, PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e36c66ca7242a17fe80b68e57f24395dbaaa6953"
   },
   "outputs": [],
   "source": [
    "features['A5'] = (full['Ticket_short'] == 'A5').astype(int)\n",
    "features['PC'] = (full['Ticket_short'] == 'PC').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c3f7c3a29a6deec89a94ff50658e296a48c968b"
   },
   "source": [
    "### Further exploring the relationship between Pclass, Sex, Age and Survival\n",
    "I suspect that some sort of interaction may exist between PClass, Sex and Age on predicitng survival. It is plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab30b1eda98fe02aa1a753f2f8916fa7f5509564",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot number of survived passengers by PClass, Sex and Age\n",
    "facet = sns.FacetGrid(full, row = 'Pclass',col='Sex', hue = 'Survived', aspect=2, palette = 'Set1')\n",
    "facet.map(plt.hist, 'Age', histtype='step', bins = np.arange(0,80,4))\n",
    "\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23c3a50b9b55c6bb337e98e950ca3a7f55ba02c8"
   },
   "source": [
    "Findings: \n",
    "- Agree with the \"Women first\" pattern. <br>\n",
    "- Child survival advantage seems to apply for those < 12 years old for male. <br>\n",
    "- Much higher survival rate for people in 1st and 2nd class. Children and Women in these 2 classes have a much higher survival rate (some age range even with  100%), compared to those in the 3rd class (which has around 50% chance). Still, some women did not survive in the 1st and 2nd class, perhaps they were in a really bad location on the boat, even they live near the deck level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "407fa91fc0f1fd998b84fea7ca6a01659b1a6852"
   },
   "source": [
    "### Age and Sex\n",
    "Instead of count of passangers survived, ploting the rate of survival with Age may give us a clearer look on the effect of age on survival rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bfe97abc89c6d22f19d5c8d2b88d19a19a70057",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Age Quartiles\n",
    "Age_quartile = pd.qcut(full.Age,10)\n",
    "\n",
    "# Plot age quartiles by sex with survival rate\n",
    "sns.barplot(data = full, x= Age_quartile, y='Survived', hue = 'Sex');\n",
    "plt.axhline(y=0.3838, color='k', linestyle='--')\n",
    "plt.xticks(rotation = 30)\n",
    "plt.title('Across All Classes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60504c3d7c37e8e6087cb4638fcd1a578f10a514"
   },
   "source": [
    "From the FacetGrid and the bar plot above, it seems that age does not matter on rate of survival for female. For male, Survival advantage for males seem to appy for those with Age < 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f686d50f3e366824c7796560be9c5dc4a00c15ab"
   },
   "source": [
    "## Feature Engineering 1\n",
    "After a brief look of relationships between the existing features, it's time to engineer some new features from the existing features to improve the predictive power of the model.\n",
    "\n",
    "First of all, we can try to extract the title of passengers from the name. Apart from seeing their predicting power, this can give us information about the pasenger's age,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8dd41b4da4fd631a36bbfc21d0c7c80e02034da",
    "scrolled": false
   },
   "source": [
    "### Title - Filling Missing Age\n",
    "Titles of the Passengers may give us valuable information to infer the missing age, e.g., Master is a title for children. Additonally, royalties and officials may have a higher priority to get on the lifeboats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d39265c950a72b2e01332e70d0b4429132b24745"
   },
   "outputs": [],
   "source": [
    "# Parse Titles from Names\n",
    "def parse_title(str):\n",
    "    m = re.search(', (\\w+ *\\w*)\\.',str)\n",
    "    return m.group(1)\n",
    "    \n",
    "title = full.Name.map(parse_title)\n",
    "title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6aba745d92667f934b5b33aaeffdb465b47c10f"
   },
   "outputs": [],
   "source": [
    "# Simplify title groups\n",
    "dict_Title = {\"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "                    }\n",
    "\n",
    "title = title.map(dict_Title)\n",
    "\n",
    "# Plot the distribution of Age by Title\n",
    "plt.figure(figsize = (14,6))\n",
    "sns.violinplot(x = title, y = full['Age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cec0493ba279552f07c4db6fd4cbc143dfd579e"
   },
   "source": [
    "Passengers with title 'Master' are likely to be children, we can infer those missing age as the mean age of Master\n",
    "Passengers with title 'Miss' seem to comprise both children and adult, the followings is an attempt to infer their age from other given features <br>\n",
    "However, age of female here is relatively unimportant, since all female regardless of age have high priority to board the lifeboats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35bf087cdaf8a71ed970ba591de7bdf178b2d1cd"
   },
   "outputs": [],
   "source": [
    "# Calculate mean age of each title group\n",
    "df_title = pd.DataFrame(title).join(full[['Age','Survived']])\n",
    "dict_age = df_title.groupby('Name').Age.mean()\n",
    "\n",
    "# Fill in Age according to passenger's title\n",
    "idx = full.Age.isnull()\n",
    "full.loc[idx,'Age'] = df_title.loc[idx, 'Name'].map(dict_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01c2aa152c2e3afcd59999291575b58536b1fdc3"
   },
   "source": [
    "### Title - Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a1080fc8016a688bd132dd7d56ffe867ed0e0e4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot title with Survived\n",
    "sns.barplot(data = df_title, x= 'Name', y='Survived');\n",
    "plt.axhline(y=0.3838, color='k', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "472e0f95ea9f8349a3e1e84b9a694a38370fff23"
   },
   "outputs": [],
   "source": [
    "# Record useful features in features dataframe\n",
    "features['Title'] = df_title['Name']\n",
    "features['Child'] = (full['Age'] <= 14).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b391071fe359f9b37a791f57a9f8d3c240fb28d1"
   },
   "source": [
    "## Feature Engineering 2\n",
    "Another  interesting relationships to look at is between Survival, Parch and SibSp. It is not difficult to imagine those within the same family/ same group will stay together when in danger, thus, having any of them survived would mean the other members of the group will likely to have a better chance to survive, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c94a0e278723eb0939bf5b8dea48d80a1d5599c"
   },
   "source": [
    "### Surname\n",
    "First, parse the Surnames of the passengers. Those from the same family should share the surname. <br>\n",
    "Surnames are grouped together and their occurance caluculated respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "759350d828967d136cac8925e4fe3204b840e123",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to parse surname of the passengers\n",
    "def parse_surname(name):\n",
    "    return name.split(',')[0]\n",
    "# Calculate Family Size\n",
    "family = pd.DataFrame(full[['Parch','SibSp','Ticket']])\n",
    "family['Family_size'] = 1 + family.Parch + family.SibSp\n",
    "\n",
    "# Parse Surname from Name\n",
    "family['Surname'] = full.Name.map(parse_surname)\n",
    "\n",
    "# Surname Code and Surname Size\n",
    "dict_scount = dict(family.groupby('Surname').Family_size.count())\n",
    "dict_scode = dict(zip(dict_scount.keys(), range(len(dict_scount))))\n",
    "\n",
    "family['Surname_code'] = family['Surname'].map(dict_scode)\n",
    "family['Surname_count'] = family['Surname'].map(dict_scount)\n",
    "\n",
    "# Examples with common surname\n",
    "display(full[family.Surname == 'Smith'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f96f1673da854fbde9c12d40697e2a3d72c0e07b"
   },
   "source": [
    "However, some common surnames may be shared by people from different families. <br> \n",
    "The following function is an attempt to address this issue: <br>\n",
    "To judge if passengers are likely to be in the same family, the function check their ticket code.  <br>\n",
    "The function decides if people with the same surname are from the same family by checking the level of  similarity of their tickets. Those with the exact same tickets or tickets that have values close to each other are grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "782101a2709ddc00f0acf4aa832970401a728e6b"
   },
   "outputs": [],
   "source": [
    "def tick2fam_gen(df):\n",
    "    \"\"\"\n",
    "    Function to judge if passengers are likely to be in the same family.\n",
    "    Input: DataFrame with Passenger surname and ticket\n",
    "    Return: Code generated to specify different families\n",
    "    \"\"\"\n",
    "    # initialize ticket dict\n",
    "    dict_tick2fam = {'000000': 0}\n",
    "    fam_counter = 0\n",
    "        \n",
    "    for i in df.index:    \n",
    "        keys = list(dict_tick2fam.keys())\n",
    "        chk_key = df.loc[i, 'Ticket']\n",
    "        for key in keys:\n",
    "            if len(chk_key) == len(key): #if their tickets have high similarity\n",
    "                if (chk_key[-4:].isdigit()) & (key[-4:].isdigit()): \n",
    "                    if (chk_key[:-2] == key[:-2]) & (np.abs(int(chk_key[-2:]) - int(key[-2:])) <= 10):\n",
    "                        dict_tick2fam[chk_key] = dict_tick2fam[key]\n",
    "                        break\n",
    "                    \n",
    "            if key == keys[-1]: # no match, assign a new code to the passenger\n",
    "                fam_counter += 1\n",
    "                dict_tick2fam[chk_key] = str(fam_counter)  \n",
    "                \n",
    "    return dict_tick2fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64f041efd25375dc455b2493fd175f4adf390f3d"
   },
   "outputs": [],
   "source": [
    "# Single out Surnames with size > true family size (may have more than 1 family involved)\n",
    "surname2chk = family[family['Family_size'] < family['Surname_count']].Surname.unique() \n",
    "# chk_surname2 = family_infer[family['FamilySize'] > family['SurnameSize']].Surname.unique() # unidentified fam\n",
    "\n",
    "# Regrouping Families according to Family Size and Ticket.\n",
    "family['Surname_adj'] = family['Surname'] #new column for corrected family_group\n",
    "\n",
    "for s in surname2chk:\n",
    "    family_regroup = family[family['Surname'] == s] #get family with specific surname\n",
    "    fam_code_dict = tick2fam_gen(family_regroup) #pass in df to get family codes within the same surname\n",
    "\n",
    "    for idx in family_regroup.index: #assign family code 1by1\n",
    "        curr_ticket = full.loc[idx].Ticket\n",
    "        fam_code = fam_code_dict[curr_ticket]\n",
    "\n",
    "        if family_regroup.loc[idx, 'Family_size'] == 1: #for passengers traveling alone\n",
    "            #relatives that shares surname and ticket, which Parch and SibSp failed to record\n",
    "            if family_regroup.Ticket.value_counts()[curr_ticket] > 1: \n",
    "                family.loc[idx, 'Surname_adj'] =  s + '-hidfam' + fam_code\n",
    "            #single traveler\n",
    "            else: \n",
    "                family.loc[idx, 'Surname_adj'] =  s + '-single' + fam_code\n",
    "        #different families\n",
    "        else: \n",
    "            family.loc[idx, 'Surname_adj'] =  s + '-fam' + fam_code\n",
    "\n",
    "display(family[family.Surname == 'Smith'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c756c44a5b9bf63d37883e683a6cb407e55ff742"
   },
   "source": [
    "After Adjusting the surnames of families, group these true families together again. The no. of families here should increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46ec707ddbd7384935354f87613ca3db2f4a8165"
   },
   "outputs": [],
   "source": [
    "# Assign codes to families\n",
    "dict_fcount = dict(family.groupby('Surname_adj').Family_size.count())\n",
    "dict_fcode = dict(zip(dict_fcount.keys(), range(len(dict_fcount))))\n",
    "\n",
    "family['Family_code'] = family['Surname_adj'].map(dict_fcode)\n",
    "family['Family_count'] = family['Surname_adj'].map(dict_fcount)\n",
    "\n",
    "print(f\"No. of Family Before Regrouping: {len(family.Surname_code.unique())}\")\n",
    "print(f\"No. of Family After Regrouping: {len(family.Family_code.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c188cc03a6cfa68ba3b32e0654acf9b56b18d1f3"
   },
   "source": [
    "### Identify Roomates by Ticket\n",
    "People who share the same ticket can be families as well as friends traveling together. They are expected to stay together during the incidents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3a0be42b0982f5399d4276de792392e6ac0541e"
   },
   "outputs": [],
   "source": [
    "# Identify Groups (Those holding the same ticket code, could be friends/family)\n",
    "group = pd.DataFrame(family[['Surname_code','Surname_count','Family_code','Family_count']])\n",
    "\n",
    "dict_tcount = dict(full.groupby('Ticket').PassengerId.count())\n",
    "dict_tcode = dict(zip(dict_tcount.keys(),range(len(dict_tcount))))\n",
    "\n",
    "group['Ticket_code'] = full.Ticket.map(dict_tcode)\n",
    "group['Ticket_count'] = full.Ticket.map(dict_tcount)\n",
    "\n",
    "print(f\"No. of Tickets Identified: {len(group['Ticket_code'].unique())}\")\n",
    "display(full[(full.Ticket == 'A/4 48871') |(full.Ticket == 'A/4 48873')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "784eda64614a50ad5aa9b14d019557b207bb510b"
   },
   "source": [
    "### Combining Friends and Families as Groups\n",
    "Finally, the families and friend groups are combined together.  <br>\n",
    "People who share either the same room or same family are grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3f4520f65551ea20fc043f1bf095159cd05b2ee"
   },
   "outputs": [],
   "source": [
    "def ChainCombineGroups(df, colA, colB):\n",
    "    '''\n",
    "    This function takes in 2 columns of labels and chain all items which share\n",
    "    the same labels within each of the 2 columns\n",
    "    input:\n",
    "    df - DataFrame\n",
    "    colA - Key for Col\n",
    "    colB - Key for Col  \n",
    "    output:\n",
    "    array of numeric grouping labels\n",
    "    '''\n",
    "    # make a copy of DFs for iteration\n",
    "    data = df.copy()\n",
    "    search_df = data.copy()\n",
    "    \n",
    "    group_count = 0\n",
    "\n",
    "    while not search_df.empty:\n",
    "\n",
    "        # Initiate pool and Select Reference item\n",
    "        pool = search_df.iloc[:1]\n",
    "        idx = pool.index\n",
    "\n",
    "        # Remove 1st item from searching df\n",
    "        search_df.drop(index = idx, inplace = True)\n",
    "\n",
    "        # Initialize Search\n",
    "        flag_init = 1\n",
    "        update = pd.DataFrame()\n",
    "\n",
    "        # While loop to exhausively search for commonalities, pool is updated until no more common features are found\n",
    "        while (flag_init or not update.empty):\n",
    "\n",
    "            flag_init = 0\n",
    "\n",
    "            # target labels to look for\n",
    "            pool_A_uniq = np.unique(pool[colA])\n",
    "            pool_B_uniq = np.unique(pool[colB])\n",
    "\n",
    "            for col in [colA,colB]:\n",
    "                idx = []\n",
    "\n",
    "                # get all indexs of items with the same label\n",
    "                for num in np.unique(pool[col]):\n",
    "                    idx.extend(search_df[search_df[col] == num].index)\n",
    "\n",
    "                # update pool\n",
    "                update = search_df.loc[idx]\n",
    "                pool = pd.concat([pool, update], axis = 0)\n",
    "\n",
    "                # remove item from searching df\n",
    "                search_df = search_df.drop(index = idx)\n",
    "\n",
    "            # assign group num\n",
    "            data.loc[pool.index, 'Group_'] = group_count\n",
    "\n",
    "        group_count += 1\n",
    "        \n",
    "    return np.array(data['Group_'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf81ffee070583626c9b09d231f98cb3f8f8e265",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign Final group no.\n",
    "group['Group_code'] = ChainCombineGroups(group, 'Family_code', 'Ticket_code')\n",
    "\n",
    "# Calculate group sizes\n",
    "dict_gcount = dict(group.groupby('Group_code').Family_code.count())\n",
    "group['Group_count'] = group.Group_code.map(dict_gcount)\n",
    "         \n",
    "print(f\"Family: {len(family['Family_code'].unique())}\")\n",
    "print(f\"Group: {len(group['Ticket_code'].unique())}\")\n",
    "print(f\"Combined: {len(group['Group_code'].unique())}\\n\")\n",
    "print('An example of grouping the both friends and family under a same group:')\n",
    "display(pd.concat([full['Ticket'],family[['Surname','Family_code']],group[['Ticket_code','Group_code']]], axis = 1)[group['Group_code'] == 458])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65dba7925fc034944ea32589d8fb6d24b7cc80b1"
   },
   "source": [
    "### Limitations:\n",
    "The above function did fail to join some families back together, especially those who had different ticket numbers and had different surnames. <br> \n",
    "For example, female siblings who were married and took different surnames; <br>\n",
    "and families who bought tickets with codes that has low similarity, which is likely to be found for those in the 1st Class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0431962860b148be85946adbf3f03fdafa2d9ef4"
   },
   "source": [
    "### Survival of the Group\n",
    "Finally, the thing that we wanted to know in the first place is if the members in their Family/Friends group has survived or not. Having a surviving friend/family member should have good predictive power of whether a passenger survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f44b3fa558cd495e13565397243757d6d896cfd7"
   },
   "outputs": [],
   "source": [
    "# Prepare the df by adding the Survived features\n",
    "group_final = pd.concat([family[['Surname_code','Surname_count','Family_code','Family_count']],\n",
    "                       group[['Ticket_code','Ticket_count','Group_code','Group_count']],\n",
    "                        full['Survived']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b71e42b2974eb853d764d7b376cc028a60970b8a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in [('Surname_code','Surname_count'),\n",
    "              ('Family_code','Family_count'),\n",
    "              ('Ticket_code','Ticket_count'),\n",
    "              ('Group_code','Group_count')]: # keep group at last\n",
    "    \n",
    "    # No. of member survived in each group\n",
    "    n_member_survived_by_gp = group_final.groupby(param[0]).Survived.sum()\n",
    "    \n",
    "    # No. of member survived in a particular group, discounting the passenger concerned\n",
    "    n_mem_survived = group_final[param[0]].map(n_member_survived_by_gp)\n",
    "    n_mem_survived_adj = n_mem_survived - group_final.Survived.apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "    # Same for the dead\n",
    "    n_member_dead_by_gp = group_final.groupby(param[0]).Survived.count() - group_final.groupby(param[0]).Survived.sum()\n",
    "    n_mem_dead  = group_final[param[0]].map(n_member_dead_by_gp)\n",
    "    n_mem_dead_adj = n_mem_dead - group_final.Survived.apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    # How many people from that group that we do not have data on.\n",
    "    unknown_factor = (group_final[param[1]] - n_mem_survived_adj - n_mem_dead_adj)/group_final[param[1]]\n",
    "    confidence = 1 - unknown_factor\n",
    "\n",
    "    # Ratio of members survived in that group, ranging from -1 to 1, adjusted by the confidence weight\n",
    "    key = 'Confidence_member_survived'+'_'+param[0]\n",
    "    ratio = (1/group_final[param[1]]) * (n_mem_survived_adj - n_mem_dead_adj)\n",
    "    group_final[key] = confidence * ratio\n",
    "\n",
    "# Display Correlation\n",
    "plt.barh(group_final.corr().Survived[-4:].index, group_final.corr().Survived[-4:])\n",
    "plt.xlabel('Correlation with Survived');\n",
    "\n",
    "features['Cf_mem_survived'] = group_final['Confidence_member_survived_Group_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ded4eaeb81d3ce81ec3ec865fa4aa04e4a05a1e9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features['Parch'] = full['Parch']\n",
    "features['SibSp'] = full['SibSp']\n",
    "features['Group_size'] = group['Group_count']\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f1d02d3ae8eee0f4d3ac606ea8c9812c5347ab6d"
   },
   "source": [
    "## Data Transformation\n",
    "Used StanardScalar for continuous variables and One-hot encoding for Categorical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd3765b2215c705a41193ea631c26fab5eb3e8b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the continuous variables\n",
    "scalar = StandardScaler()\n",
    "features_z_transformed = features.copy()\n",
    "continuous = ['Fare'] \n",
    "features_z_transformed[continuous] = scalar.fit_transform(features_z_transformed[continuous])\n",
    "\n",
    "# Transform Sex labels into binary code\n",
    "features_z_transformed.Sex = features_z_transformed.Sex.apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "# One-hot Encoding\n",
    "features_final = pd.get_dummies(features_z_transformed)\n",
    "\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Seperate Train Data and Test Data\n",
    "features_final_train = features_final[:891]\n",
    "features_final_test = features_final[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01cfc65eded30aeb785046e01591d713ea441086"
   },
   "source": [
    "## Model Training and Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46541bd74d5e886853601434987b126c444797be"
   },
   "outputs": [],
   "source": [
    "# Spliting Training Sets into Train and Cross-validation sets\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final_train, \n",
    "                                                    train.Survived, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6e4f58b457d4094bb16b848f4212a69b0fb3910"
   },
   "outputs": [],
   "source": [
    "# Create Model Training Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    \n",
    "    # then get predictions on the training samples(X_train)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "            \n",
    "    # Compute accuracy on the training samples\n",
    "    results['acc_train'] = accuracy_score(y_train, predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples. Acc: {:.4f}\".format(learner.__class__.__name__, sample_size, results['acc_test']))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7515c55d4c3d55d39d50f5ae0fcff497b627a86f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier,RandomForestClassifier\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = GradientBoostingClassifier(random_state = 0)\n",
    "clf_B = LogisticRegression(random_state= 0)\n",
    "clf_C = RandomForestClassifier(random_state= 0)\n",
    "\n",
    "# Calculate the number of samples for 10%, 50%, and 100% of the training data\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)/2)\n",
    "samples_1 = int(len(y_train)/10)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "024d7f953b517522e4299275a569ad08457b921b"
   },
   "outputs": [],
   "source": [
    "# Reshaping the Results for plotting\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in results.items():\n",
    "    temp = pd.DataFrame(i[1]).rename(columns={0:'1% of train', 1:'10% of train', 2:'100% of train'})\n",
    "    temp['model'] = i[0]\n",
    "    df = pd.concat([df, temp], axis = 0)\n",
    "df_plot = df.reset_index().melt(id_vars=['index','model'])\n",
    "\n",
    "# Ploting the results\n",
    "fig, axs = plt.subplots(1,2,figsize = (16,5))\n",
    "for i,key in enumerate(df_plot['index'].unique()[:2]):\n",
    "    ax = axs[i%2]\n",
    "    sns.barplot(data = df_plot[df_plot['index'] == key], x = 'model', y = 'value',\n",
    "                hue = 'variable', ax = ax)\n",
    "    ax.set_ylim([0.6,1])\n",
    "    ax.set_title(key)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f642f0d6f052b42b12ec340fb0e0682c50fca74"
   },
   "source": [
    "## Model Selection and model tuning\n",
    "RandomForestClassifier seemed to have the best out of the box accuracy score and with room for improvement as seen in acc_train.\n",
    "Model tuning is performed using GridSearchCV to improve generalizability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50dad97e49723373414d910c553cf71de0f43681"
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0, oob_score = True)\n",
    "\n",
    "parameters = {'criterion' :['gini'],\n",
    "             'n_estimators' : [350], #400\n",
    "             'max_depth':[5], #5\n",
    "             'min_samples_leaf': [4], #4\n",
    "              'max_leaf_nodes': [10], #10]\n",
    "              'min_impurity_decrease': [0], #0\n",
    "              'max_features' : [1] #1\n",
    "             }\n",
    "\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring = scorer, cv = 10)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"Oob score on testing data: {:.4f}\".format(clf.oob_score_))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final oob score on the testing data: {:.4f}\".format(best_clf.oob_score_))\n",
    "print(\"\\nBest Parameters\\n------\")\n",
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4222258b969f99892223eff198fc96fac98c2ec7"
   },
   "outputs": [],
   "source": [
    "# Output for Kaggle competition\n",
    "final_predict = best_clf.predict(features_final_test)\n",
    "\n",
    "prediction = pd.DataFrame(full[891:].PassengerId)\n",
    "prediction['Survived'] = final_predict.astype('int')\n",
    "\n",
    "prediction.to_csv('predict.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
